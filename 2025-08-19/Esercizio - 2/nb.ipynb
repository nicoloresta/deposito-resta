{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d53bc150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9873823",
   "metadata": {},
   "source": [
    "# Dataset Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31828501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9471 entries, 0 to 9470\n",
      "Data columns (total 17 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Date           9357 non-null   object \n",
      " 1   Time           9357 non-null   object \n",
      " 2   CO(GT)         9357 non-null   object \n",
      " 3   PT08.S1(CO)    9357 non-null   float64\n",
      " 4   NMHC(GT)       9357 non-null   float64\n",
      " 5   C6H6(GT)       9357 non-null   object \n",
      " 6   PT08.S2(NMHC)  9357 non-null   float64\n",
      " 7   NOx(GT)        9357 non-null   float64\n",
      " 8   PT08.S3(NOx)   9357 non-null   float64\n",
      " 9   NO2(GT)        9357 non-null   float64\n",
      " 10  PT08.S4(NO2)   9357 non-null   float64\n",
      " 11  PT08.S5(O3)    9357 non-null   float64\n",
      " 12  T              9357 non-null   object \n",
      " 13  RH             9357 non-null   object \n",
      " 14  AH             9357 non-null   object \n",
      " 15  Unnamed: 15    0 non-null      float64\n",
      " 16  Unnamed: 16    0 non-null      float64\n",
      "dtypes: float64(10), object(7)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "            Date      Time CO(GT)  PT08.S1(CO)  NMHC(GT) C6H6(GT)  \\\n",
      "0     10/03/2004  18.00.00    2,6       1360.0     150.0     11,9   \n",
      "1     10/03/2004  19.00.00      2       1292.0     112.0      9,4   \n",
      "2     10/03/2004  20.00.00    2,2       1402.0      88.0      9,0   \n",
      "3     10/03/2004  21.00.00    2,2       1376.0      80.0      9,2   \n",
      "4     10/03/2004  22.00.00    1,6       1272.0      51.0      6,5   \n",
      "...          ...       ...    ...          ...       ...      ...   \n",
      "9466         NaN       NaN    NaN          NaN       NaN      NaN   \n",
      "9467         NaN       NaN    NaN          NaN       NaN      NaN   \n",
      "9468         NaN       NaN    NaN          NaN       NaN      NaN   \n",
      "9469         NaN       NaN    NaN          NaN       NaN      NaN   \n",
      "9470         NaN       NaN    NaN          NaN       NaN      NaN   \n",
      "\n",
      "      PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  \\\n",
      "0            1046.0    166.0        1056.0    113.0        1692.0   \n",
      "1             955.0    103.0        1174.0     92.0        1559.0   \n",
      "2             939.0    131.0        1140.0    114.0        1555.0   \n",
      "3             948.0    172.0        1092.0    122.0        1584.0   \n",
      "4             836.0    131.0        1205.0    116.0        1490.0   \n",
      "...             ...      ...           ...      ...           ...   \n",
      "9466            NaN      NaN           NaN      NaN           NaN   \n",
      "9467            NaN      NaN           NaN      NaN           NaN   \n",
      "9468            NaN      NaN           NaN      NaN           NaN   \n",
      "9469            NaN      NaN           NaN      NaN           NaN   \n",
      "9470            NaN      NaN           NaN      NaN           NaN   \n",
      "\n",
      "      PT08.S5(O3)     T    RH      AH  Unnamed: 15  Unnamed: 16  \n",
      "0          1268.0  13,6  48,9  0,7578          NaN          NaN  \n",
      "1           972.0  13,3  47,7  0,7255          NaN          NaN  \n",
      "2          1074.0  11,9  54,0  0,7502          NaN          NaN  \n",
      "3          1203.0  11,0  60,0  0,7867          NaN          NaN  \n",
      "4          1110.0  11,2  59,6  0,7888          NaN          NaN  \n",
      "...           ...   ...   ...     ...          ...          ...  \n",
      "9466          NaN   NaN   NaN     NaN          NaN          NaN  \n",
      "9467          NaN   NaN   NaN     NaN          NaN          NaN  \n",
      "9468          NaN   NaN   NaN     NaN          NaN          NaN  \n",
      "9469          NaN   NaN   NaN     NaN          NaN          NaN  \n",
      "9470          NaN   NaN   NaN     NaN          NaN          NaN  \n",
      "\n",
      "[9471 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('./rsc/AirQualityUCI.csv', sep=';')\n",
    "print(dataset.info())\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca0e0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9357 entries, 0 to 9356\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Date     9357 non-null   object \n",
      " 1   Time     9357 non-null   object \n",
      " 2   NO2(GT)  9357 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 292.4+ KB\n",
      "None\n",
      "            Date      Time  NO2(GT)\n",
      "0     10/03/2004  18.00.00    113.0\n",
      "1     10/03/2004  19.00.00     92.0\n",
      "2     10/03/2004  20.00.00    114.0\n",
      "3     10/03/2004  21.00.00    122.0\n",
      "4     10/03/2004  22.00.00    116.0\n",
      "...          ...       ...      ...\n",
      "9352  04/04/2005  10.00.00    190.0\n",
      "9353  04/04/2005  11.00.00    179.0\n",
      "9354  04/04/2005  12.00.00    175.0\n",
      "9355  04/04/2005  13.00.00    156.0\n",
      "9356  04/04/2005  14.00.00    168.0\n",
      "\n",
      "[9357 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select only Date, Time, NO2 columns\n",
    "dataset = dataset[['Date', 'Time', 'NO2(GT)']].dropna()\n",
    "print(dataset.info())\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d85d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Date  NO2(GT)\n",
      "0    2004-03-10 18:00:00    113.0\n",
      "1    2004-03-10 19:00:00     92.0\n",
      "2    2004-03-10 20:00:00    114.0\n",
      "3    2004-03-10 21:00:00    122.0\n",
      "4    2004-03-10 22:00:00    116.0\n",
      "...                  ...      ...\n",
      "9352 2005-04-04 10:00:00    190.0\n",
      "9353 2005-04-04 11:00:00    179.0\n",
      "9354 2005-04-04 12:00:00    175.0\n",
      "9355 2005-04-04 13:00:00    156.0\n",
      "9356 2005-04-04 14:00:00    168.0\n",
      "\n",
      "[9357 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create a unified Date column of type Date - specificando il formato\n",
    "dataset['Date'] = pd.to_datetime(\n",
    "    dataset['Date'] + ' ' + dataset['Time'], \n",
    "    format='%d/%m/%Y %H.%M.%S'\n",
    ")\n",
    "dataset = dataset[['Date', 'NO2(GT)']]\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2716b1ab",
   "metadata": {},
   "source": [
    "# Computing Classification Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5875a783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Date  NO2(GT)  Global_Average  Daily_Average  \\\n",
      "0    2004-03-10 18:00:00    113.0       58.148873     108.833333   \n",
      "1    2004-03-10 19:00:00     92.0       58.148873     108.833333   \n",
      "2    2004-03-10 20:00:00    114.0       58.148873     108.833333   \n",
      "3    2004-03-10 21:00:00    122.0       58.148873     108.833333   \n",
      "4    2004-03-10 22:00:00    116.0       58.148873     108.833333   \n",
      "...                  ...      ...             ...            ...   \n",
      "9352 2005-04-04 10:00:00    190.0       58.148873     122.000000   \n",
      "9353 2005-04-04 11:00:00    179.0       58.148873     122.000000   \n",
      "9354 2005-04-04 12:00:00    175.0       58.148873     122.000000   \n",
      "9355 2005-04-04 13:00:00    156.0       58.148873     122.000000   \n",
      "9356 2005-04-04 14:00:00    168.0       58.148873     122.000000   \n",
      "\n",
      "      Weekly_Average Quality_vs_Global Quality_vs_Daily Quality_vs_Weekly  \n",
      "0          95.892157              poor             poor              poor  \n",
      "1          95.892157              poor             good              good  \n",
      "2          95.892157              poor             poor              poor  \n",
      "3          95.892157              poor             poor              poor  \n",
      "4          95.892157              poor             poor              poor  \n",
      "...              ...               ...              ...               ...  \n",
      "9352      122.000000              poor             poor              poor  \n",
      "9353      122.000000              poor             poor              poor  \n",
      "9354      122.000000              poor             poor              poor  \n",
      "9355      122.000000              poor             poor              poor  \n",
      "9356      122.000000              poor             poor              poor  \n",
      "\n",
      "[9357 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset['Global_Average'] = dataset['NO2(GT)'].mean()\n",
    "dataset['Daily_Average'] = dataset.groupby(dataset['Date'].dt.date)['NO2(GT)'].transform('mean')\n",
    "dataset['Weekly_Average'] = dataset.groupby(pd.Grouper(key='Date', freq='W'))['NO2(GT)'].transform('mean')\n",
    "\n",
    "# Classification based on different averages\n",
    "dataset['Quality_vs_Global'] = dataset['NO2(GT)'].apply(\n",
    "    lambda x: 'good' if x <= dataset['Global_Average'].iloc[0] else 'poor'\n",
    ")\n",
    "\n",
    "dataset['Quality_vs_Daily'] = dataset.apply(\n",
    "    lambda row: 'good' if row['NO2(GT)'] <= row['Daily_Average'] else 'poor', \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "dataset['Quality_vs_Weekly'] = dataset.apply(\n",
    "    lambda row: 'good' if row['NO2(GT)'] <= row['Weekly_Average'] else 'poor', \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b43b901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality_vs_Global\n",
      "poor    6771\n",
      "good    2586\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Quality_vs_Daily\n",
      "poor    5233\n",
      "good    4124\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Quality_vs_Weekly\n",
      "poor    5415\n",
      "good    3942\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification statistics\n",
    "print(dataset['Quality_vs_Global'].value_counts(), end='\\n\\n')\n",
    "\n",
    "print(dataset['Quality_vs_Daily'].value_counts(), end='\\n\\n')\n",
    "\n",
    "print(dataset['Quality_vs_Weekly'].value_counts(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e186267",
   "metadata": {},
   "source": [
    "# Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84eca033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  Hour  NO2_Value Quality_Weekly\n",
      "0     2004-03-10    21      122.0           poor\n",
      "1     2004-03-10    22      116.0           poor\n",
      "2     2004-03-10    20      114.0           poor\n",
      "3     2004-03-11    19      172.0           poor\n",
      "4     2004-03-11    20      165.0           poor\n",
      "...          ...   ...        ...            ...\n",
      "1168  2005-04-03    19      181.0           poor\n",
      "1169  2005-04-03    21      158.0           poor\n",
      "1170  2005-04-04    10      190.0           poor\n",
      "1171  2005-04-04     9      187.0           poor\n",
      "1172  2005-04-04    11      179.0           poor\n",
      "\n",
      "[1173 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "peak_hours = []\n",
    "\n",
    "# Raggruppa per data (solo giorno, senza orario)\n",
    "for date, group in dataset.groupby(dataset['Date'].dt.date):\n",
    "    # Ordina per NO2 in ordine decrescente e prendi le prime 3\n",
    "    top_3 = group.nlargest(3, 'NO2(GT)')\n",
    "    \n",
    "    # Aggiungi informazioni sulle ore di picco\n",
    "    for idx, row in top_3.iterrows():\n",
    "        peak_hours.append({\n",
    "            'Date': date,\n",
    "            'Hour': row['Date'].hour,\n",
    "            'NO2_Value': row['NO2(GT)'],\n",
    "            'Quality_Weekly': row['Quality_vs_Weekly']\n",
    "        })\n",
    "\n",
    "print(pd.DataFrame(peak_hours))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42630462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Week  Total_Hours  Poor_Hours  Poor_Percentage  Global_Average  \\\n",
      "0   2004-W11          102          70        68.627451       57.871113   \n",
      "1   2004-W12          168          99        58.928571       57.871113   \n",
      "2   2004-W13          168         114        67.857143       57.871113   \n",
      "3   2004-W14          168         124        73.809524       57.871113   \n",
      "4   2004-W15          168         126        75.000000       57.871113   \n",
      "5   2004-W16          168          99        58.928571       57.871113   \n",
      "6   2004-W17          168          65        38.690476       57.871113   \n",
      "7   2004-W18          168         105        62.500000       57.871113   \n",
      "8   2004-W19          168         117        69.642857       57.871113   \n",
      "9   2004-W20          168         126        75.000000       57.871113   \n",
      "10  2004-W21          168         101        60.119048       57.871113   \n",
      "11  2004-W22          168          99        58.928571       57.871113   \n",
      "12  2004-W23          168         122        72.619048       57.871113   \n",
      "13  2004-W24          168          94        55.952381       57.871113   \n",
      "14  2004-W25          168         102        60.714286       57.871113   \n",
      "15  2004-W26          168         102        60.714286       57.871113   \n",
      "16  2004-W27          168          99        58.928571       57.871113   \n",
      "17  2004-W28          168          98        58.333333       57.871113   \n",
      "18  2004-W29          168         102        60.714286       57.871113   \n",
      "19  2004-W30          168          92        54.761905       57.871113   \n",
      "20  2004-W31          168         113        67.261905       57.871113   \n",
      "21  2004-W32          168         128        76.190476       57.871113   \n",
      "22  2004-W33          168         113        67.261905       57.871113   \n",
      "23  2004-W34          168          61        36.309524       57.871113   \n",
      "24  2004-W35          168         118        70.238095       57.871113   \n",
      "25  2004-W36          168          41        24.404762       57.871113   \n",
      "26  2004-W37          168          59        35.119048       57.871113   \n",
      "27  2004-W38          168         112        66.666667       57.871113   \n",
      "28  2004-W39          168          93        55.357143       57.871113   \n",
      "29  2004-W40          168          98        58.333333       57.871113   \n",
      "30  2004-W41          168          77        45.833333       57.871113   \n",
      "31  2004-W42          168          33        19.642857       57.871113   \n",
      "32  2004-W43          168          99        58.928571       57.871113   \n",
      "33  2004-W44          168          97        57.738095       57.871113   \n",
      "34  2004-W45          168          94        55.952381       57.871113   \n",
      "35  2004-W46          168         118        70.238095       57.871113   \n",
      "36  2004-W47          168          98        58.333333       57.871113   \n",
      "37  2004-W48          168          87        51.785714       57.871113   \n",
      "38  2004-W49          168          98        58.333333       57.871113   \n",
      "39  2004-W50          168         114        67.857143       57.871113   \n",
      "40  2004-W51          168          93        55.357143       57.871113   \n",
      "41  2004-W52          168         105        62.500000       57.871113   \n",
      "42  2004-W53          120          24        20.000000       57.871113   \n",
      "43  2005-W01          168         108        64.285714       57.871113   \n",
      "44  2005-W02          168         111        66.071429       57.871113   \n",
      "45  2005-W03          168          95        56.547619       57.871113   \n",
      "46  2005-W04          168          96        57.142857       57.871113   \n",
      "47  2005-W05          168          94        55.952381       57.871113   \n",
      "48  2005-W06          168          84        50.000000       57.871113   \n",
      "49  2005-W07          168         102        60.714286       57.871113   \n",
      "50  2005-W08          168          95        56.547619       57.871113   \n",
      "51  2005-W09          168          98        58.333333       57.871113   \n",
      "52  2005-W10          168          96        57.142857       57.871113   \n",
      "53  2005-W11          168          90        53.571429       57.871113   \n",
      "54  2005-W12          168          78        46.428571       57.871113   \n",
      "55  2005-W13          168          86        51.190476       57.871113   \n",
      "56  2005-W14           15           8        53.333333       57.871113   \n",
      "57  2005-W53           48          45        93.750000       57.871113   \n",
      "\n",
      "    Difference_from_Global  Above_Global_Average  \n",
      "0                10.756338                  True  \n",
      "1                 1.057459                  True  \n",
      "2                 9.986030                  True  \n",
      "3                15.938411                  True  \n",
      "4                17.128887                  True  \n",
      "5                 1.057459                  True  \n",
      "6               -19.180636                 False  \n",
      "7                 4.628887                  True  \n",
      "8                11.771745                  True  \n",
      "9                17.128887                  True  \n",
      "10                2.247935                  True  \n",
      "11                1.057459                  True  \n",
      "12               14.747935                  True  \n",
      "13               -1.918732                 False  \n",
      "14                2.843173                  True  \n",
      "15                2.843173                  True  \n",
      "16                1.057459                  True  \n",
      "17                0.462221                  True  \n",
      "18                2.843173                  True  \n",
      "19               -3.109208                 False  \n",
      "20                9.390792                  True  \n",
      "21               18.319364                  True  \n",
      "22                9.390792                  True  \n",
      "23              -21.561589                 False  \n",
      "24               12.366983                  True  \n",
      "25              -33.466351                 False  \n",
      "26              -22.752065                 False  \n",
      "27                8.795554                  True  \n",
      "28               -2.513970                 False  \n",
      "29                0.462221                  True  \n",
      "30              -12.037779                 False  \n",
      "31              -38.228255                 False  \n",
      "32                1.057459                  True  \n",
      "33               -0.133017                 False  \n",
      "34               -1.918732                 False  \n",
      "35               12.366983                  True  \n",
      "36                0.462221                  True  \n",
      "37               -6.085398                 False  \n",
      "38                0.462221                  True  \n",
      "39                9.986030                  True  \n",
      "40               -2.513970                 False  \n",
      "41                4.628887                  True  \n",
      "42              -37.871113                 False  \n",
      "43                6.414602                  True  \n",
      "44                8.200316                  True  \n",
      "45               -1.323493                 False  \n",
      "46               -0.728255                 False  \n",
      "47               -1.918732                 False  \n",
      "48               -7.871113                 False  \n",
      "49                2.843173                  True  \n",
      "50               -1.323493                 False  \n",
      "51                0.462221                  True  \n",
      "52               -0.728255                 False  \n",
      "53               -4.299684                 False  \n",
      "54              -11.442541                 False  \n",
      "55               -6.680636                 False  \n",
      "56               -4.537779                 False  \n",
      "57               35.878887                  True  \n",
      "Global Poor Quality Percentage: 57.871112536069255\n"
     ]
    }
   ],
   "source": [
    "# Calcolo percentuale di ore di scarsa qualità per settimana vs media globale\n",
    "def calculate_weekly_poor_quality_stats(df):\n",
    "    # Aggiungi colonna settimana\n",
    "    df['Week'] = df['Date'].dt.isocalendar().week\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Year_Week'] = df['Year'].astype(str) + '-W' + df['Week'].astype(str).str.zfill(2)\n",
    "    \n",
    "    # Calcola percentuale globale di ore con scarsa qualità\n",
    "    global_poor_percentage = (df['Quality_vs_Weekly'] == 'poor').mean() * 100\n",
    "    \n",
    "    # Calcola statistiche settimanali\n",
    "    weekly_stats = []\n",
    "    \n",
    "    for week, group in df.groupby('Year_Week'):\n",
    "        total_hours = len(group)\n",
    "        poor_hours = (group['Quality_vs_Weekly'] == 'poor').sum()\n",
    "        poor_percentage = (poor_hours / total_hours) * 100\n",
    "        \n",
    "        # Confronto con la media globale\n",
    "        difference_from_global = poor_percentage - global_poor_percentage\n",
    "        \n",
    "        weekly_stats.append({\n",
    "            'Week': week,\n",
    "            'Total_Hours': total_hours,\n",
    "            'Poor_Hours': poor_hours,\n",
    "            'Poor_Percentage': poor_percentage,\n",
    "            'Global_Average': global_poor_percentage,\n",
    "            'Difference_from_Global': difference_from_global,\n",
    "            'Above_Global_Average': poor_percentage > global_poor_percentage\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(weekly_stats), global_poor_percentage\n",
    "\n",
    "weekly_stats_df, global_poor_percentage = calculate_weekly_poor_quality_stats(dataset)\n",
    "print(weekly_stats_df)\n",
    "print(\"Global Poor Quality Percentage:\", global_poor_percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a28dc0",
   "metadata": {},
   "source": [
    "# Dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ed84094a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 7485\n",
      "Test set size: 1872\n"
     ]
    }
   ],
   "source": [
    "# Preparazione delle feature\n",
    "# Estraiamo componenti temporali dalla data\n",
    "dataset['Hour'] = dataset['Date'].dt.hour\n",
    "dataset['DayOfWeek'] = dataset['Date'].dt.dayofweek\n",
    "dataset['Month'] = dataset['Date'].dt.month\n",
    "\n",
    "# Features per il modello\n",
    "X = dataset[['Hour', 'DayOfWeek', 'Month', 'NO2(GT)']]\n",
    "# X = dataset[['Date', 'NO2(GT)']]\n",
    "y = dataset['Quality_vs_Weekly']\n",
    "\n",
    "# Encoding della variabile target\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# Split dei dati\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e8be3",
   "metadata": {},
   "source": [
    "# DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "26c3f0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       0.85      0.89      0.87       789\n",
      "        poor       0.92      0.89      0.90      1083\n",
      "\n",
      "    accuracy                           0.89      1872\n",
      "   macro avg       0.89      0.89      0.89      1872\n",
      "weighted avg       0.89      0.89      0.89      1872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creazione e addestramento del modello Decision Tree\n",
    "dt_model = DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    max_depth=10,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Predizioni e valutazione\n",
    "dt_pred = dt_model.predict(X_test)\n",
    "print(classification_report(y_test, dt_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ecea1f",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "45927819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       0.84      0.73      0.78       789\n",
      "        poor       0.82      0.90      0.86      1083\n",
      "\n",
      "    accuracy                           0.82      1872\n",
      "   macro avg       0.83      0.81      0.82      1872\n",
      "weighted avg       0.83      0.82      0.82      1872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "print(classification_report(y_test, lr_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d9092",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c7a7841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       0.86      0.86      0.86       789\n",
      "        poor       0.90      0.90      0.90      1083\n",
      "\n",
      "    accuracy                           0.88      1872\n",
      "   macro avg       0.88      0.88      0.88      1872\n",
      "weighted avg       0.88      0.88      0.88      1872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, rf_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5536c93",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "110fdce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       0.86      0.89      0.87       789\n",
      "        poor       0.92      0.89      0.91      1083\n",
      "\n",
      "    accuracy                           0.89      1872\n",
      "   macro avg       0.89      0.89      0.89      1872\n",
      "weighted avg       0.89      0.89      0.89      1872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Standardizzazione delle feature (importante per MLP)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Creazione e addestramento del modello MLP\n",
    "mlp_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),  # Due layer nascosti con 100 e 50 neuroni\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    batch_size='auto',\n",
    "    learning_rate='constant',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predizioni e valutazione\n",
    "mlp_pred = mlp_model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, mlp_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c44e0e",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fc366fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       0.87      0.89      0.88       789\n",
      "        poor       0.92      0.91      0.91      1083\n",
      "\n",
      "    accuracy                           0.90      1872\n",
      "   macro avg       0.90      0.90      0.90      1872\n",
      "weighted avg       0.90      0.90      0.90      1872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creazione e addestramento del modello XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predizioni e valutazione\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "print(classification_report(y_test, xgb_pred, target_names=le.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
